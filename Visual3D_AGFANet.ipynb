{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cuda\n",
      "file_list_img  shape: 1000\n",
      "len(dataloader_img : 1\n",
      "len(dataloader_mask : 1\n",
      "test_img :  torch.Size([1, 1, 275, 512, 512])\n",
      "test_mask :  torch.Size([1, 1, 275, 512, 512])\n",
      "pred_patches shape: (18, 128, 160, 160)\n",
      "img_patches shape: (18, 128, 160, 160)\n",
      "mask_patches shape: (18, 128, 160, 160)\n",
      "merge: 2 3 3\n",
      "pred_merged_volume   max value : 1.0\n",
      "pred_merged_volume shape: (275, 512, 512)\n",
      "merge: 2 3 3\n",
      "img_merged_volume shape: (275, 512, 512)\n",
      "merge: 2 3 3\n",
      "mask_merged_volume shape: (275, 512, 512)\n",
      "-------------------------Dice :  0.8515542121031267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caee93cd39034a96bfe7955c7723de05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8daafd0e8bc459fa543f1a54cf1101e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from model.AGFANet import AGFANet                            ##有个问题，train的时候喂进model的是 h,w,d，   现在是 d,h,w \n",
    "import k3d\n",
    "import numpy as np\n",
    "from k3d import matplotlib_color_maps\n",
    "import torch \n",
    "import numpy as np \n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage.measure import label\n",
    "from PIL import Image\n",
    "import glob \n",
    "import torch.nn as nn \n",
    "import matplotlib.pyplot as plt \n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "import nibabel as nib\n",
    "import itk\n",
    "import pickle\n",
    "import shutil\n",
    "import os\n",
    "import gzip\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import argparse\n",
    "import torch.distributed as dist\n",
    "from model.unet3d import UNet3D\n",
    "# from dataloader.npy_3d_Loader import Data\n",
    "from utils.train_metrics import metrics3d\n",
    "from utils.losses import WeightedCrossEntropyLoss, DiceLoss\n",
    "from torch.optim import lr_scheduler\n",
    "import datetime\n",
    "from torch.utils.data import random_split\n",
    "from utils.sliding_window import sliding_window_3d\n",
    "import torch.nn as nn\n",
    "from dataloader.npy_3d_Loader import *\n",
    "# import pandas as pd\n",
    "from postprocess.keep_the_largest_area import get_aorta_branch\n",
    "from postprocess.keep_the_largest_area import backpreprcess as postprocess\n",
    "from postprocess.get_patch import get_patch_new\n",
    "from utils.evaluation_metrics3D import metrics_3d, Dice, over_rate, under_rate\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device is \" + str(device))\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "batch_size = 1\n",
    "batch_size_new=1\n",
    "num_epochs=1   #  600\n",
    "patch_size = [128, 160, 160]  \n",
    "overlap_size=[32, 40, 40]  \n",
    "best_score = [0]\n",
    "args = {\n",
    "    # 'data_path': 'cta_project/data/npy',\n",
    "    'epochs': 10,\n",
    "    'input_shape': (128, 160, 160),\n",
    "    'snapshot': 10,\n",
    "    'test_step': 1,\n",
    "    'model_path': '/home/lxy/lxy/001_CASnet/save_models_randomcrop',\n",
    "    'batch_size': 1,  # VNet 1 other 2\n",
    "    'folder': 'folderFRM',\n",
    "    'model_name': 'CSNet3D',  #UNet3D   CSNet3D\n",
    "}\n",
    "ckpt_path = os.path.join(args['model_path'], args['model_name'] + '_' + args['folder'])\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_folder,file_list, transform=None):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.data_folder=data_folder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_list[idx]\n",
    "        file_path = os.path.join(self.data_folder, file_name)\n",
    "\n",
    "        nii_data = itk.array_from_image(itk.imread(file_path))\n",
    "\n",
    "        if self.transform:\n",
    "            nii_data = self.transform(nii_data)\n",
    "\n",
    "        nii_tensor = torch.from_numpy(nii_data).float()\n",
    "        nii_tensor = nii_tensor.unsqueeze(0)\n",
    "        # train_mask = nii_tensor.unsqueeze(0)\n",
    "\n",
    "        return nii_tensor\n",
    "\n",
    "def save_ckpt(net, iter):\n",
    "    if not os.path.exists(ckpt_path):\n",
    "        os.makedirs(ckpt_path)\n",
    "    date = datetime.datetime.now().strftime(\"%Y-%m-%d-\")\n",
    "    # torch.save(model.state_dict(),PATH)\n",
    "    torch.save(net.state_dict(), os.path.join(ckpt_path, date + iter + '.pkl'))\n",
    "    print(\"{} Saved model to:{}\".format(\"\\u2714\", ckpt_path))\n",
    "\n",
    "class MinMaxScale:\n",
    "    def __call__(self, img):\n",
    "        min_val = img.min()\n",
    "        max_val = img.max()\n",
    "        img = (img - min_val) / (max_val - min_val)\n",
    "        return img\n",
    "min_max_transform = MinMaxScale()\n",
    "Test_Model = {'AGFANet': AGFANet,\n",
    "              'UNet3D': UNet3D\n",
    "              }\n",
    "def load_net():\n",
    "    model = Test_Model[args['model_name']](2, 1).cuda()\n",
    "    ckpt_path = os.path.join(args['model_path'], args['model_name'] + '_' + args['folder'])\n",
    "    # modelname = ckpt_path + '/' + 'best_score' + '_checkpoint300epo.pkl'\n",
    "    modelname = ckpt_path + '/' + '2024-03-30-30.pkl' \n",
    "\n",
    "    model = nn.DataParallel(model)\n",
    "    checkpoint = torch.load(modelname)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    return model\n",
    "\n",
    "data_folder = '/home/lxy/lxy/data_CCTA/train'\n",
    "data_folder2 = '/home/lxy/lxy/data_CCTA/trainMask'\n",
    "file_list_img = [f for f in os.listdir(data_folder) if f.endswith('.nii.gz')]\n",
    "file_list_mask = [f for f in os.listdir(data_folder2) if f.endswith('.nii.gz')]\n",
    "file_list_img=sorted(file_list_img)\n",
    "file_list_mask=sorted(file_list_mask)\n",
    "print('file_list_img  shape:', len(file_list_img))  # 1000\n",
    "\n",
    "test_size = 883\n",
    "test_img_list = file_list_img[0:1]\n",
    "test_mask_list = file_list_mask[0:1]\n",
    "\n",
    "dataset_img = CustomDataset(data_folder,test_img_list, transform=min_max_transform)\n",
    "dataset_mask = CustomDataset(data_folder2,test_mask_list)\n",
    "\n",
    "# dataloader\n",
    "dataloader_img = DataLoader(dataset_img, batch_size=batch_size, shuffle=False)  # here must be False, follow the name\n",
    "dataloader_mask = DataLoader(dataset_mask, batch_size=batch_size, shuffle=False)\n",
    "print(\"len(dataloader_img :\",len(dataloader_img))\n",
    "print(\"len(dataloader_mask :\",len(dataloader_mask))\n",
    "iter_img = iter(dataloader_img)\n",
    "iter_mask = iter(dataloader_mask)\n",
    "\n",
    "#load model\n",
    "net = load_net()\n",
    "DSC_Dice_mean=[]\n",
    "def Dice(pred, gt):\n",
    "    pred = np.int64(pred / 255)\n",
    "    gt = np.int64(gt / 255)\n",
    "    dice = np.sum(pred[gt == 1]) * 2.0 / (np.sum(pred) + np.sum(gt))\n",
    "    return dice\n",
    "def get_metrics(pred, gt):\n",
    "    pred[pred > 0] = 255\n",
    "    gt[gt > 0] = 255\n",
    "    Ur = under_rate(pred, gt)\n",
    "    Or = over_rate(pred, gt)\n",
    "    dice = Dice(pred, gt)\n",
    "    tp, fn, fp, IoU = metrics_3d(pred, gt)\n",
    "    return tp, fn, fp, IoU, dice, Or, Ur\n",
    "def get_prediction(pred):\n",
    "    pred = torch.argmax(pred, dim=1)\n",
    "    mask = (pred.data.cpu().numpy() * 255).astype(np.uint8)\n",
    "    # print(np.max(mask),np.min(mask))\n",
    "    mask = mask.squeeze(0)  # for CE Loss\n",
    "    return mask\n",
    "def MinMaxScale(img):\n",
    "        min_val = img.min()\n",
    "        max_val = img.max()\n",
    "        img = (img - min_val) / (max_val - min_val)\n",
    "        return img\n",
    "\n",
    "def merge_patches(patches, volume_size, overlap_size):\n",
    "    \"\"\"\n",
    "    Merge the cropped patches into a complete 3D volume.\n",
    "    Args:\n",
    "        patches (np.ndarray): the cropped patches, with shape [num_patches, patch_width, patch_height, patch_depth]\n",
    "        volume_size (tuple or list): the size of the complete volume, with format [width, height, depth]\n",
    "        overlap_size (tuple or list): the size of overlap between adjacent patches, with format [overlap_width, overlap_height, overlap_depth]\n",
    "    Returns:\n",
    "        np.ndarray: the merged volume, with shape [width, height, depth]\n",
    "    \"\"\"\n",
    "    depth, height, width = volume_size\n",
    "    patch_depth, patch_height, patch_width = patches.shape[1:]\n",
    "    overlap_depth, overlap_height, overlap_width = overlap_size\n",
    "    num_patches_z = (depth - patch_depth) // (patch_depth - overlap_depth) + 1\n",
    "    num_patches_x = (height - patch_height) // (patch_height - overlap_height) + 1\n",
    "    num_patches_y = (width - patch_width) // (patch_width - overlap_width) + 1\n",
    "    \n",
    "    \n",
    "    print('merge:', num_patches_z, num_patches_x, num_patches_y)\n",
    "    merged_volume = np.zeros(volume_size)\n",
    "    weight_volume = np.zeros(volume_size)   \n",
    "    idx = 0\n",
    "    for z in range(num_patches_z):\n",
    "        for x in range(num_patches_x):\n",
    "            for y in range(num_patches_y):\n",
    "                z_start = z * (patch_depth - overlap_depth)\n",
    "                x_start = x * (patch_height - overlap_height)\n",
    "                y_start = y * (patch_width - overlap_width)\n",
    "\n",
    "                merged_volume[z_start:z_start+patch_depth, x_start:x_start+patch_height, y_start:y_start+patch_width] += patches[idx]\n",
    "                weight_volume[z_start:z_start+patch_depth, x_start:x_start+patch_height, y_start:y_start+patch_width] += 1\n",
    "                idx += 1\n",
    "    merged_volume /= (weight_volume + 1e-10)   \n",
    "    return merged_volume\n",
    "\n",
    "def custom_round_array(array):\n",
    "    result = np.empty_like(array)  \n",
    "    for i in range(array.shape[0]):  \n",
    "        for j in range(array.shape[1]):  \n",
    "            for k in range(array.shape[2]):  \n",
    "                value = array[i, j, k]  \n",
    "                integer_part = int(value)  \n",
    "                decimal_part = value - integer_part  \n",
    "                if decimal_part < 0.4:\n",
    "                    result[i, j, k] = integer_part\n",
    "                else:\n",
    "                    result[i, j, k] = integer_part + 1\n",
    "    return result\n",
    "\n",
    "test_img = next(iter_img)  # [1, 1, 512, 512, 275]\n",
    "test_mask = next(iter_mask)\n",
    "Dice_mean=[]\n",
    "\n",
    "# for batch_idx in range(len(dataloader_img)):  # 10\n",
    "for batch_idx in range(1):  # 10  len(dataloader_img)\n",
    "    TP, FN, FP, Dice = [], [], [], []\n",
    "\n",
    "    print(\"test_img : \",test_img.shape) # torch.Size([1, 1, 206, 512, 512])\n",
    "    print(\"test_mask : \",test_mask.shape)\n",
    "    \n",
    "    # sliding window\n",
    "    batchSize,channel, depth, height, width = test_img.shape\n",
    "    # volume_size = test_img.shape # (275, 512, 512)\n",
    "    volume_size=[depth,height, width]\n",
    "    # volume_size=np.asarray(volume_size)\n",
    "    overlap_depth, overlap_height, overlap_width = overlap_size\n",
    "    d_patch, h_patch, w_patch = patch_size\n",
    "    # patch_width, patch_height, patch_depth = patch_size\n",
    "\n",
    "    img_patches = []\n",
    "    pred_patches = []\n",
    "    mask_patches = []\n",
    "    count=0\n",
    "\n",
    "    for d in range(0, depth - d_patch + 1, d_patch - overlap_depth):\n",
    "        for h in range(0, height - h_patch + 1, h_patch - overlap_height):\n",
    "            for w in range(0, width - w_patch + 1, w_patch - overlap_width):\n",
    "                \n",
    "                \n",
    "                img_patch = test_img[:,:, d:d + d_patch, h:h + h_patch, w:w + w_patch]\n",
    "                # patch = volume[x:x+patch_width, y:y+patch_height, z:z+patch_depth]\n",
    "                mask_patch= test_mask[:,:,d:d + d_patch, h:h + h_patch, w:w + w_patch]\n",
    "                # print(\"img_patch shape: \",img_patch.shape) #torch.Size([96, 96, 96])      [1, 1, 96, 96, 96])\n",
    "\n",
    "                img_patch2=img_patch.squeeze(0)\n",
    "                img_patch2=img_patch2.squeeze(0)\n",
    "                img_patch_npy=img_patch2.numpy()\n",
    "                mask_patch2=mask_patch.squeeze(0)\n",
    "                mask_patch2=mask_patch2.squeeze(0)\n",
    "                mask_patch_npy=mask_patch2.numpy()\n",
    "                # mask_patch_npy=mask_patch.detach().cpu().numpy()\n",
    "                img_patch = img_patch.to(device)\n",
    "\n",
    "                pred_patch= net(img_patch)\n",
    "                pred_patch = torch.argmax(pred_patch, dim=1) \n",
    "                pred_patch=pred_patch.squeeze(0)     \n",
    "                # max_v=pred_patch.max()\n",
    "                # pred_patch[pred_patch < 0.7] = 0\n",
    "                # pred_patch[pred_patch >= 0.7] = 1\n",
    "                pred_patch=pred_patch.detach().cpu()\n",
    "\n",
    "                pred_patch_npy=pred_patch.numpy()\n",
    "                pred_patches.append(pred_patch_npy)  \n",
    "                img_patches.append(img_patch_npy)\n",
    "                mask_patches.append(mask_patch_npy)\n",
    "\n",
    "    pred_patches = np.asarray(pred_patches)\n",
    "    max_v= np.max(pred_patches)\n",
    "    img_patches = np.asarray(img_patches)\n",
    "    mask_patches = np.asarray(mask_patches)\n",
    "    print('pred_patches shape:', pred_patches.shape)          # (147, 96, 96, 96)  \n",
    "    print('img_patches shape:', img_patches.shape)   #   \n",
    "    print('mask_patches shape:', mask_patches.shape)   #   \n",
    "\n",
    "    pred_merged_volume = merge_patches(pred_patches, volume_size, overlap_size)  # \n",
    "    # pred_merged_volume=np.uint8(np.round(pred_merged_volume)) \n",
    "    pred_merged_volume=custom_round_array(pred_merged_volume)\n",
    "\n",
    "    print(\"pred_merged_volume   max value :\",np.max(pred_merged_volume))\n",
    "    print('pred_merged_volume shape:', pred_merged_volume.shape)  # (275, 512, 512)\n",
    "    img_merged_volume = merge_patches(img_patches, volume_size, overlap_size)\n",
    "    print('img_merged_volume shape:', img_merged_volume.shape)  # (275, 512, 512)\n",
    "    mask_merged_volume = merge_patches(mask_patches, volume_size, overlap_size)\n",
    "    # mask_merged_volume=np.uint8(mask_merged_volume)\n",
    "    print('mask_merged_volume shape:', mask_merged_volume.shape)  # (275, 512, 512)\n",
    "\n",
    "    labeled_volume = label(pred_merged_volume, connectivity=3) \n",
    "    unique_labels, label_counts = np.unique(labeled_volume, return_counts=True)\n",
    "    min_volume_threshold = 3000  \n",
    "\n",
    "    for label, count in zip(unique_labels, label_counts):\n",
    "        if count < min_volume_threshold:\n",
    "            pred_merged_volume[labeled_volume == label] = 0\n",
    "\n",
    "    intersection=(pred_merged_volume * mask_merged_volume).sum()\n",
    "    Dice= (2*intersection)/(pred_merged_volume.sum()+mask_merged_volume.sum())\n",
    "    Dice_mean.append(Dice)\n",
    "\n",
    "    print(\"-------------------------Dice : \", Dice) # \n",
    "\n",
    "    pred_downsampled = pred_merged_volume[::2, ::2, ::2]\n",
    "    img_downsampled = img_merged_volume[::2, ::2, ::2]\n",
    "    mask_downsampled = mask_merged_volume[::2, ::2, ::2]\n",
    "\n",
    "    plot = k3d.plot()\n",
    "    volume = k3d.volume(pred_downsampled.astype(np.float32), color_map=k3d.basic_color_maps.Jet)\n",
    "    plot += volume\n",
    "    plot.display()\n",
    "\n",
    "    plot3 = k3d.plot()\n",
    "    volume3 = k3d.volume(mask_downsampled.astype(np.float32), color_map=k3d.basic_color_maps.Jet)\n",
    "    plot3 += volume3\n",
    "    plot3.display()\n",
    "      \n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8779ea1df19946a79bc02aced57e8435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot3 = k3d.plot()\n",
    "# fig = plt.figure(facecolor='black')\n",
    "plt.style.use('dark_background')\n",
    "volume3 = k3d.volume(mask_downsampled.astype(np.float32), color_map=k3d.basic_color_maps.Jet)\n",
    "plot3 += volume3\n",
    "plot3.display()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eae634c70c74276bf35b27d173055e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot3 = k3d.plot()\n",
    "# fig = plt.figure(facecolor='black')\n",
    "plt.style.use('dark_background')\n",
    "volume3 = k3d.volume(pred_downsampled.astype(np.float32), color_map=k3d.basic_color_maps.Jet)\n",
    "plot3 += volume3\n",
    "plot3.display()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Baseline: second   2024-05-04-10\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
